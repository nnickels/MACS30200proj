---
title: "A comparative digital survey investigation of the construct validity of the Trait Anxiety Inventory within a UChicago community sample and an MTurk sample"  
author: "Nora Nickels"
date: "6/6/2018"
header-includes:
    - \usepackage{setspace}
output: pdf_document
bibliography: references.bib
---

\doublespacing

# Abstract  

In psychological and biological research, quantitative scales are used to measure individual differences in stable traits across populations. In our research, our lab seeks to measure trait anxiety as a potential stable trait that may predict how individuals respond to acute anxiety. However, we are often concerned over both the construct validity of our measures, as well as the ability to consider our findingds as external valid outside of a "WEIRD" (western, educated, industrialized, rich, democratic) population of a University community. In this study, we ask the following questions: 1) Do distributions of trait anxiety scores differ between samples acquired from a University of Chicago community vs. the Amazon Mechanical Turk (MTurk) community? 2) How strong is the construct validity of the Trait Anxiety Inventory in a sample drawn from these two populations; specifically, do setting and mood relate to trait anxiety responses of UChicago or MTurk community members when the Trait Anxiety Inventory is completed outside of a controlled laboratory setting? We found that individuals from a University of Chicago community sample and individuals from an MTurk sample do not significantly differ in trait anxiety scores. Further, we found that positive and negative acute mood are the strongest predictors of trait anxiety scores amongst various demographic and extraneous measures that have the potential to affect trait anxiety scores when measured digitally. These results are an important explorative first step in the study of how digital measurement of personality traits have the potential ability to introduce extraneous variables when digitally measuring what should theoretically be stable inherent traits. 

\pagebreak  

# Introduction

In psychological and biological research, emotions are measured both in terms of acute states of arousal and in terms of individual differences in the propensity to experience that emotion. Scientists define the difference between these two elements of emotional measurement as state and trait measures of emotions. For example, anxiety as an emotion can be generally defined as heightened feelings of tension, apprehension, and worry, in combination with an aroused physiological state [@spielberger2010state]. It is particularly important to distinguish between state and trait for anxiety, as higher trait anxiety, or higher individual proneness to experience anxiety, could affect the way an individual reacts behaviorally in both acute and long term situations. Trait anxiety can be defined as an individual measure of intensity and frequency of experienced anxiety, which involves these feelings of apprehension and heightened response of the autonomic nervous system [@spielberger1966theory]. Importantly, trait anxiety is seen as a relatively *stable* trait, and individuals who have higher trait anxiety tend to perceive situations as more dangerous or stressful over time [@spielberger1966theory].

The State-Trait Anxiety Inventory, or STAI, is a long-standing measure that uses two scales to report these two measures (state anxiety and trait anxiety)[@spielberger1989state]. The STAI is designed as a self-report measure, with items that map specifically onto the two factors of anxiety. The STAI trait scale consists of twenty statements that have individuals rate, on a four-point Likert scale, different statements about how they feel generally (e.g., "I feel nervous and restless."). Both the state and trait scales of the STAI are long-standing, frequently used scales in psychology, and theoretically, the inventory has been shown to measure response to experimental manipulation in meaningful ways [@chapman1977determinants]. Further, the two subscales have been shown to correlate with other measures of anxiety that is consistent the content of measure [@bieling1998state]. 

Importantly, retest correlations of the iventory have shown strong reliability, and re-test coefficients for the trait scale have shown to be even higher for those items that measure the trait scale [@spielberger2010state; @barnes2002reliability]. The STAI is reported to have high validity, with concurrent validity with other anxiety questionnaires reported as ranging from 0.73 - 0.85 [@bieling1998state]. However, some researchers argue that a general, yet incorrect, implication that is attached to re-test reliability is that which assumes that once an instrument is found to be reliable, its reliability does or cannot change [@barnes2002reliability]. If reliability is simply a property of scores from a specific sample of survey-takers, as opposed to being a property of the test itself, then reliability of a measure can be affected by any source of variability that also affects the scores (e.g., demographics in a particular sample, such as gender, age, motivation, mood, etc.)[@barnes2002reliability]. Therefore, although re-test reliability and concurrent measures of validity are incredibly important, considering the specific sample involved in one's study is crucial in discussion of the interpretation of one's results. 

In my work, I share equal concern in that my specific sample is taken from a community whose specific demographics may affect the distribution of anxiety scores. Like most psychology study populations, our work frequently involves participant samples drawn from a university setting. Specifically, the University of Chicago ranks as one of the top undergraduate research institutions in the U.S., and is often viewed as a competitive and stressful environment. Beyond the concern that many research institutions have about their willing research participants coming from a primarily Western, educated, industrialized, rich, and democractic (WEIRD) population [@jones2010weird], our lab also deals with the concern of recruiting willing participants from a sample that may not only have higher than usual scores of trait anxiety, but also have rapidly fluctuating rates of both state and trait anxiety throughout their academic experience.

To control some of these concerns of validity and reliability, researchers often use a controlled, laboratory setting, to remove extraneous effects of the environment. For example, our laboratory has research participants spend about twenty-five minutes in the laboratory before first saliva samples are taken, to reduce the potential for effects outside of the lab to result in hormonal concentrations that do not represent true baseline. In this way, we also administer many psychological surveys in the lab as well. Howevers, due to both time and monetary restraints, we occasionally adminster *trait* based questionnaires digitally in advance of the lab session, as trait based questionaires theoretically measure relatively stable personality measures. 

Digital surveys and digital ethnographic methods are seen as new technologies for social research that allow scientists to avoid more costly research methods, to easily alter questionnaires to access different cultural groups, to access hard-to-reach populations, to collect higher response rates, and to consolidate data more quickly and efficiently [@murthy2008digital]. In the case of administering our surveys digitally outside of the lab, we save both temporal and monetary costs, yet run the risk of extraneous factors of the environment interacting with demographics of our sample and therefore affecting the trait anxiety scores of our participants. If certain factors environmentally outside of a controlled laboratory could affect trait anxiety scores, then we experience a trade off of losing validity when our survey is administered digitally.

Obviously, our sample taken from the University of Chicago community is not the only sample from which digital survey data is drawn. Digitally web-based data collection is a relatively new method that contains the primary elements needed to conduct social scientific research, while benefitting from the same aspects discussed above. In fact, despite the concerns of losing the control of a laboratory environment, some researchers have argued that survey data that is digitally collected are in fact preferred to data that has been collected in-person. For example, Castler et al. compared data that had been collected in the lab and also online, and found that the test results themselves resulted in equivalent, high-quality data for both groups, and that the data collected digitally was in fact more socioeconomically and ethnically diverse [-@casler2013separate]. Further, Hauser and Schwarz found that data digitally collected using Amazon's Mechanical Turk (MTurk) showed higher rates of participant attentiveness (measured using attentiveness an instructional manipulation check) when compared to data collected from college students [-@hauser2016attentive]. 

On the other hand, other research that compares samples collected from digital populations with in-person samples have found differences that may be less beneficial. Further, even if both samples are collected digitally but come from differing populations, the samples themselves may compare and contrast in interesting ways, based on the population from which the digital survey sample is taken. For example, Goodman and colleagues compared MTurk participants with student samples on multiple measures, including attentiveness, personality, and certain decision-making biases [-@goodman2013data]. The authors found that MTurk participants were actually less attentive and had different personality profiles (e.g., less extroverted, less emotionally stable) when compared to a student population, but were similar in terms of how they value money and time and in terms of their risk aversion [@goodman2013data].  

Clearly then, the results of this line of research have been mixed thus far. What we can confirm is that much of the literature focusing on the strengths and weaknesses of digital data has focused specifically on globally digital as opposed to local populations, where data can be crowdsourced or collected in a completely digital way. Conducting psychology research using crowdsourced data has largely revolved around the Amazon Mechanical Turk (MTurk) platform, based on its popularity and ease of access.  MTurk provides a platform to outsource small tasks (referred to as HITS, or human intelligence tasks) to a workforce collected globally that is made up of "workers" [@behrend2011viability]. The MTurk platform has been investigated to confirm that it provides an efficient and reliable alternative from the university participant population [@behrend2011viability; @rand2012promise]. Further, MTurk has been used to successfully replicate experimental work, showing its viability in terms of experimental design and validity flexibility [@berinsky2012evaluating].  

In particular, a solid amount of work has been done investigating the specific MTurk population, focusing on the demographics, responsivity, and motivation of the community of MTurk workers. Many studies show that the demographics of MTurk workers fluctuate, and that depending on the research questions being asked, researchers must use caution when selecting participants by filtering targeted study pools on MTurk [@huff2015these; @ross2010crowdworkers; @casey2017intertemporal; ]. Others suggest that the pros and cons of using the MTurk pool are based on both controllable and uncontrollable factors, and that often the benefits, such as accessing hard-to-reach populations, exceed the downsides of the use of in-person populations and lab studies [@paolacci2014inside; @smith2015convenient]. Fields of psychology, political science, and industrial / organization psychology in particular pay particular attention to the personality characterisics and ideology of the MTurk pool, as those factors are incredibly important when considering the external validity of individual characteristics of one's research participants [@bates2013conducting; @clifford2015samples; @woo2015amazon]. Overall, there has been much discussion regarding the methodology of MTurk sampling and the MTurk population, as its promise of accessing high quality, inexpensive data is ground breaking to many lines of research [@buhrmester2011amazon].

Based on this literature and common restrictions of both money and time, our lab continues to have standing concerns based on the comparison between our sample population, drawn from the UChicago community and containing many undergraduate college students, and a sample population coming from a wider population, such as the the MTurk commmunity. Past research has discussed the pros and cons of data collection from in-person vs. digital methodologies, and it is critical to know the specific descriptive statistics of a specific sampling frame, and how these descriptions differ from other sample populations, such as a wider and argulably more externally valid, global community. In particular, our use of psychology research is invested in stable personality, emotional, and psychological traits that map on to biological and behavioral responses. Therefore, we are focused on the distribution of stable traits in our population, how this distribution differs from other samples, and how the scores that lead to this distribution are impacted by extraneous factors. This study seeks to answer, specifically, how the TAI scores of a sample from a UChicago community compare to this collected from a digitally crowdsourced sample from Amazon Mechanical Turk. These comparisons in scores could be tied to differences in specific anxiety traits between the two samples, or differences in diversity amongst the groups. Further, this study will look into the construct validity of both the UChicago sample and the MTurk sample, by focusing on how extraneous factors, such as setting and mood, affect the responses of the TAI for both a UChicago based sample and an MTurk collected sample. The focus on these factors will add to the literature surrounding how in-person vs. digitally collected data compare.

## Theoretical Model

Our lab's research explores stable personality, emotional, and psychological traits that map on to biological and behavioral responses. In this study, we are focused on the distribution of a stable trait (trait anxiety) in our population, how this distribution differs from other samples, and how the scores that lead to this distribution are impacted by extraneous factors. This study seeks to answer, specifically, how the TAI scores of a sample from a UChicago community compare to this collected from a digitally crowdsourced sample from Amazon Mechanical Turk. This study will look into the construct validity of both the UChicago sample and the MTurk sample, by focusing on how extraneous factors, such as setting and mood, affect the responses of the TAI for both a UChicago based sample and an MTurk collected sample. 

To do so, we will use a multiple linear regression model that will identify key variables that predict trait anxiety scores in our digital survey participants. The survey explores our main predictor variable of community or group (whether you were recruited from a UChicago population or an MTurk population), along with a variety of demographic factors that seek to control for what else may predict TAI scores. These potential predictors of our model will include age, gender, income, research participation experience, where the survey was taken (physical setting), and positive and negative acute mood. 

## Current Aims and Hypotheses

* Aim 1: To determine differences in trait anxiety score distribution between a sample collected from a University of Chicago community and a sample collected from an MTurk community. We predict that trait anxiety scores from a University of Chicago sample will be higher than scores from an MTurk sample, as University of Chicago students in an academic setting have particularly high rates of consistent stress. Consistent stress may translate as higher trait anxiety, which would argue against the construct validity of the trait anxiety inventory and measure overall.
* Aim 2: To determine the effects of demographics, acute positive and negative mood, and setting on trait anxiety scores, in addition to population group. We predict that in addition to community (UChicago vs. MTurk) having an effect on trait anxiety score, acute positive and negative mood, and environmental setting, will predict trait anxiety score. Specifically, we predict that individuals who complete digital questionnaires in a more stressful work setting (e.g., office) will have higher trait anxiety scores than individual who complete digital questionnaires in a setting such as their home or on the go.

\pagebreak  


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width=8, fig.height=6)
options(knitr.table.format = "latex")

library(tidyverse)
library(ggplot2)
library(knitr) 
library(modelr)
library(broom)
library(kableExtra)
library(dotwhisker)
library(dplyr)

set.seed(1234)

macss <- read_csv('macss.csv') %>%
  mutate(Group_binary = ifelse(Group == "UC", 0, 1)) %>%
  rename(MTurk = Group_binary) %>%
  rename(Positive_Mood = PANAS_P_TOTAL) %>%
  rename(Negative_Mood = PANAS_N_TOTAL)

desc1 <- read_csv('macss_desc_1.csv')
desc2 <- read_csv('macss_desc_2.csv')
```

# Methods

### Variables

To measures trait anxiey, we used the trait scale of the State Trait Anxiety Inventory. The STAI trait scale consists of twenty statements that have individuals rate, on a four-point Likert scale, different statements about how they feel generally (e.g., "I feel nervous and restless."). The items were randomized for each participant. To measure acute positive and negative mood of participants, we will use the Positive and Negative Affect Schedule (PANAS; Watson et al., 1988). The PANAS is a psychometric scale that measures positive and negative affect using words that describe feelings and emotions on a Likert scale of 1 (not at all) to 5 (very much). A multitude of studies have been used to confirm the reliability and validity of the PANAS. We will use the PANAS scales to measure how acute positive or negative moods affect the trait anxiety scores of the participants. PANAS measures will be collected after the TAI is administered, so as not to prime participants' with the current mood and thus affect the TAI scores. The PANAS items were also randomized for each participant.

To measure the setting of where the survey was taken, we included items asking about type of setting, the amount of people present at the time, and whether the participant was interacting wtih anyone else at the time. To measure demographics variables, we included items asking questions about age, gender, occupation, income level, relationship status, gender, and whether or not the participant has taken part in a research study prior to this one. 

## Data

### Data collection and Participants

Data from this study is collected from two different populations. One sample was collected from a population of MTurk workers, and one sample was collected from the UChicago community. Both groups completed the same survey that was administered via Qualtrics. The Qualtrics survey was anonymous, and included measures in the following order: Trait Anxiety Inventory, PANAS, questions regarding setting, and finally demographic variables. 

We surveyed 104 MTurk workers on Thursday, May 3rd of 2018. The survey was advertised as taking about 5 minutes and we paid paid respondents 15 cents each. Because we wish to benchmark MTurk against a sample of University of Chicago community members, we resitrcited the survey to individuals classified as 18 or older and living in the United States. Further, we excluded individuals with approval ratings below 90% on previous MTurk tasks. 

We surveyed 96 University of Chicago community members on Thursday, May 3rd of 2018. The survey was advertised through several platforms that are exclusively accessbily to individuals with a University of Chicago certified email address. These platforms include: UChicago Marketplace; UChicago private Facebook groups; UChicago private listservs; and UChicago current student class email lists (approved accessed by individual course instructors).

The data is accessible within our github repository: https://github.com/nnickels/MACS30200proj.

### Summary Statistics

Table 1 presents key summary statistics of demographics amongst both the UChicago and MTurk groups, as well as overall. Both samples included more females than males, with the UChicago sample having 69% female participants. The mean age of MTurk workers (37.3 years) was significantly greater than that of the UChicago participants (22.8 years), and MTurkers were more likely to be married than UChicago students (34.6% married vs. 5.2% married). Both UChicago students and MTurkers most frequent response in terms of setting where the survey was completed was at home or in their apartment. Table 2 presents key summary statistics of TAI and PANAS scores among both the UChicago and MTurk groups, as well as overall. 

```{r desc_1}

kable(desc1, format = "latex", caption = "Demographics [note]", booktabs = T) %>%
  kable_styling(latex_options = "striped") %>%
  column_spec(5, width = "5em") %>%
  column_spec(6, width = "5em") %>%
  column_spec(7, width = "5em") %>%
  add_footnote(c("Prior research experience defined as having answered yes to participanting in a research study previously."))

```

```{r desc_2}

kable(desc2, format = "latex", 
      caption = "Descriptive Statistics of TAI and PANAS Inventories [note]",
      booktabs = T) %>%
  kable_styling(latex_options = "striped") %>%
  column_spec(5, width = "5em") %>%
  column_spec(6, width = "5em") %>%
  column_spec(7, width = "5em") %>%
  add_footnote(c("Positive and Negative mood scores assessed with the positive and negative scales of the PANAS. TAI Total scores calculated from the Trait scale of the STAI."))

```


### Data Analysis

To compare mean TAI scores between UChicago and MTurk participants, we use a t-test of mean TAI scores between the groups. To analyze the effects of group (UChicago vs. MTurk) on TAI scores while controlling for demographics and other potential extraneous factors, we use a multiple linear regression model with TAI score as our dependent variable. Alpha was set at 0.05

\pagebreak  

# Results

Our results seek to answer the following research questions: 1) Do distributions of trait anxiety scores differ in samples acquired from a University of Chicago community vs. the Amazon Mechanial Turk community? 2) How strong is the construct validity of the Trait Anxiety Inventory in a sample drawn from these two populations; specifically, do setting and mood relate to trait anxiety responses of UChicago or MTurk community members when the T.A.I. is completed outside of a controlled laboratory setting?

In comparing average Trait Anxiety Scores between UChicago (M =  45.68) and MTurk samples (M = 45.41), we found no difference in TAI Scores between the two groups (t = -0.155, p-value = 0.877). Figure 1 shows the average TAI score between groups.   



```{r compare_groups}

macss %>%
  ggplot(aes(x = Group, y = TAI_TOTAL))+
    geom_boxplot()+
    ylab("TAI Score")+
    xlab("Participant Group")+
    ggtitle("Fig. 1: UChicago & MTurk Participants Do Not Differ in TAI Score")

```

A multiple linear regression was calculated to predict TAI scores based on Group, with further predictors of positive acute mood, negative acute mood, setting, age, income level, gender, and previous research participant experience. Table 3 presents the regression model results. A signification regression equation was found, such that positive acute mood, negative acute mood, and past research participation were all significant predictor of TAI scores, while controlling for setting, age, income, and gender. Figure 2 presents the regression results as the significance and 95% confidence intervals of the coefficient estimates for each of the predictors. Positive acute mood is a negative predictor of TAI score. Negative acute mood is a positive predicor of TAI score. Past research participant experience is a slight positive predictor of TAI score. Group (U of C vs. MTurk) is a slight negative predictor of TAI score, such that, controlling for all other model predictors, being a U of C student increases TAI score by 3.15. 

```{r model_table}

macss_full <- lm(TAI_TOTAL ~ Group + Positive_Mood + Negative_Mood + Setting + Age + Income + Gender + Research, data = macss)
tidy_macss <- tidy(macss_full)

kable(tidy_macss, format = "latex", 
      caption = "Regression Model Results",
      booktabs = T,
      longtable = T) %>%
  kable_styling(latex_options = "striped", "hold_position") %>%
  column_spec(5, width = "5em") %>%
  column_spec(6, width = "5em") %>%
  column_spec(7, width = "5em")

```




```{r model_plot}

macss_full <- lm(TAI_TOTAL ~ Group + Positive_Mood + Negative_Mood + Setting + Age + Income + Gender + Research, data = macss)

dwplot(macss_full) +
     xlab("Coefficient Estimate") + 
     ylab("Predictors") +
     geom_vline(xintercept = 0, colour = "grey60", linetype = 2) +
     ggtitle("Fig. 2: Predictors of Trait Anxiety Scores")



```


\pagebreak  

# Conclusion

In this study, we report that individuals from a University of Chicago community sample and individuals from an MTurk sample do not significantly differ in trait anxiety scores. We also report that, when controlling for demographic variables, sample group only marginally predicts trait anxiety scores. Instead, acute mood predicted trait anxiety scores, such that higher acute negative mood predicted higher trait anxiety scores and higher acute positive mood predicted lower trait anxiety scores. Past research experience also predicted trait anxiety scores, such that individuals who had past experience participating in research studies were more likely to have higher trait anxiety scores.  

This study is a first explorative step in terms of determining how separate populations differ in individual differences and how extraneous variables have the ability to affect trait measures as quantified by scales that can be administered digitally. The fact that we did not find differences in trait anxiety between sampling frames can be interpreted as a sign of the potential for strong external validity of the Trait Anxiety Inventory. For example, if we had found that University of Chicago community members had significantly lower trait anxiety levels, it would be difficult for our lab's research to be considered externally valid outside of the University of Chicago community. Instead, this finding presents hopeful usability of digital communities, such as Amazon MTurk, for specific use of trait personality questionnaires. Although the two sampling frames may differ in terms of several important demographic variables of interest, such as relationship status, age, and income levels, we can consider trait anxiety distribution between the two groups to be relatively similar so long as these demographic variables do not also correlate with trait anxiety measures.  

In attempting to explain significant predictors of trait anxiety scores, it may be that acute positive and negative mood have the strongest relationship with trait anxiety due to the fact that both acute mood and anxiety are related to affective states. Although the trait portion of the STAI is not meant to measure state anxiety, it is possible that acute, state mood has the ability to affect the way individuals answer a trait questionnaire. This suggests that we must use caution when administering trait questionnaires, particularly outside of the laboratory. There are still important benefits to administering questionnaires in a laboratory setting; bringing individuals to an emotional and biological baseline in a laboratory setting may aid in collecting valid measures of trait variables. 

In attempting to explain why the element of setting does not relate to trait anxiety scores, one possible interpretation is that the TAI is well designed to ask only about trait anxiety, and that digital administration of psychological questionnaires may be a useful and accurate way to measure psychological traits outside of a laboratory. With administering questionnaires to participants before arrival at the lab, we have concern that where they choose to take the survey (e.g., on the go, in their home, in a work setting, around other individuals, etc.) may affect they way they answer the questionnaire. For example, individuals who respond to the survey at work may feel more stressed than they do at home, and this could have been made apparent in their trait anxiety scores. However, we found no relationship between setting and trait anxiety scores. This result is promising in terms of digitally collected research, in that extraneous variables in environmental settings should not interfere with how individuals respond to research questionnaires. 

This study has several important limitations, multiple of which suggest some important next steps for future work in answering these methodological questions. First, this study utilized a between subjects design, with participants only completing the trait anxiety questionnaire once. This research would be stronger using a within subjects design where individuals are repeatedly tested on trait anxiety questionnaires multiple times, both within a lab setting and outside of a lab setting (when the questionnaire is taken digitally). It is possible that individuals' trait anxiety scores may vary from day to day, or week to week, which would argue against the construct validity of the trait anxiety inventory in general. Utilizing a future research design which could repeatedly test participants would help to answer deeper questions of validity. Second, there is a crucial difference in data collection between the two populations in terms of motivation; MTurk participants are paid, and UChicago participants filled out the questionnaire on a volunteer basis. It is important to consider this difference, as motivational changes may psychological prime individuals in ways that may alter their responses. One future study could involve bringing both samples of participants to the lab with equivalent compensation, to control for compensational changes in motivation. Finally, this study design does not involve a controlled experimental manipulation that could determine directionality or causality to connect acute mood with trait anxiety. It is possible that trait anxiety questionnaire could directly affect the responses in mood, as opposed to the other way around.


\pagebreak  
\singlespacing  

# References